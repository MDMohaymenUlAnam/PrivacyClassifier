{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nihan\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nihan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nihan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nihan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources (if not already downloaded)\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Unnamed: 0                                     review_content  \\\n",
       "0              6                                       Mark the spy   \n",
       "1              7                                              Title   \n",
       "2              9  My account says its been temporarily locked. ...   \n",
       "3             13  Put on your tin foil hats to deflect the mind ...   \n",
       "4             16  Im so sick and tired of us working our tails ...   \n",
       "...          ...                                                ...   \n",
       "6270       21666  I am currently in South Korea and As of July 2...   \n",
       "6271       21677  (?????????)Beware that the Marketplace is stea...   \n",
       "6272       21679  you know Ive had my Facebook for years full o...   \n",
       "6273       21681  Facebook is not social media now. It is Social...   \n",
       "6274       21682  To begin, I believe there has been a little im...   \n",
       "\n",
       "                    student1_email  student1annotation  \\\n",
       "0      nazifatasneem@iut-dhaka.edu                   4   \n",
       "1      nazifatasneem@iut-dhaka.edu                   4   \n",
       "2     abunomanhaider@iut-dhaka.edu                   3   \n",
       "3        antaraarifa@iut-dhaka.edu                   1   \n",
       "4        antaraarifa@iut-dhaka.edu                   4   \n",
       "...                            ...                 ...   \n",
       "6270   nabilaislam21@iut-dhaka.edu                   1   \n",
       "6271   nabilaislam21@iut-dhaka.edu                   3   \n",
       "6272    shahriarkhan@iut-dhaka.edu                   3   \n",
       "6273        minhajul@iut-dhaka.edu                   2   \n",
       "6274    xcadettasnim1834@gmail.com                   2   \n",
       "\n",
       "                   student2_email  student2annotation  \\\n",
       "0          iqramoni@iut-dhaka.edu                   4   \n",
       "1          iqramoni@iut-dhaka.edu                   4   \n",
       "2      labibahhoque@iut-dhaka.edu                   3   \n",
       "3       rifahramisa@iut-dhaka.edu                   4   \n",
       "4       rifahramisa@iut-dhaka.edu                   4   \n",
       "...                           ...                 ...   \n",
       "6270   ahababimtiaz@iut-dhaka.edu                   2   \n",
       "6271  tajwaruzzaman@iut-dhaka.edu                   2   \n",
       "6272   tasniaanower@iut-dhaka.edu                   2   \n",
       "6273      hamimsaad@iut-dhaka.edu                   1   \n",
       "6274          aslabib44@gmail.com                   4   \n",
       "\n",
       "                 student3_email  student3annotation  annotation_count  \\\n",
       "0         ishmaam@iut-dhaka.edu                   1                 3   \n",
       "1         ishmaam@iut-dhaka.edu                   4                 3   \n",
       "2     rifahramisa@iut-dhaka.edu                   2                 3   \n",
       "3      ahmedalfey@iut-dhaka.edu                   1                 3   \n",
       "4     mdabidhasan@iut-dhaka.edu                   4                 3   \n",
       "...                         ...                 ...               ...   \n",
       "6270  faizamaliat@iut-dhaka.edu                   1                 3   \n",
       "6271  faizamaliat@iut-dhaka.edu                   2                 3   \n",
       "6272       nusrat@iut-dhaka.edu                   2                 3   \n",
       "6273    hamimsaad@iut-dhaka.edu                   1                 3   \n",
       "6274  mdabidhasan@iut-dhaka.edu                   4                 3   \n",
       "\n",
       "         agreement_type  final_label  \n",
       "0     Partially Correct            4  \n",
       "1       Fully Agreement            4  \n",
       "2     Partially Correct            3  \n",
       "3     Partially Correct            1  \n",
       "4       Fully Agreement            4  \n",
       "...                 ...          ...  \n",
       "6270  Partially Correct            1  \n",
       "6271  Partially Correct            2  \n",
       "6272  Partially Correct            2  \n",
       "6273  Partially Correct            1  \n",
       "6274  Partially Correct            4  \n",
       "\n",
       "[6275 rows x 11 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Dataset\\Thesis Labeled Dataset.csv', encoding='ISO-8859-1')\n",
    "\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'review_content', 'student1_email', 'student1annotation',\n",
       "       'student2_email', 'student2annotation', 'student3_email',\n",
       "       'student3annotation', 'annotation_count', 'agreement_type',\n",
       "       'final_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Select only the 'review_content' and 'final_label' columns\n",
    "df = df[['review_content', 'final_label']]\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.to_csv('filtered_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample count: 6275\n",
      "Sentences: 26054\n",
      "Avg. words per sample: 63.69\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Load your dataset\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize counters and variables\n",
    "sample_count = len(df)\n",
    "sentence_count = 0\n",
    "total_words = 0\n",
    "\n",
    "# Process each review\n",
    "for review in df['review_content']:\n",
    "    sentences = sent_tokenize(review)\n",
    "    sentence_count += len(sentences)\n",
    "    \n",
    "    words = word_tokenize(review)\n",
    "    total_words += len(words)\n",
    "\n",
    "# Calculate metrics\n",
    "avg_words_per_sample = total_words / sample_count\n",
    "\n",
    "# Print results\n",
    "print(f\"Sample count: {sample_count}\")\n",
    "print(f\"Sentences: {sentence_count}\")\n",
    "print(f\"Avg. words per sample: {avg_words_per_sample:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'review_content', 'student1_email', 'student1annotation',\n",
       "       'student2_email', 'student2annotation', 'student3_email',\n",
       "       'student3annotation', 'annotation_count', 'agreement_type',\n",
       "       'final_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation using regular expressions\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    # Tokenization using TextBlob\n",
    "    tokens = TextBlob(text).words\n",
    "    \n",
    "    # Stemming using NLTK PorterStemmer\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    tokens = [porter_stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # Lemmatization using NLTK WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "\n",
    "df['processed_review_content'] = df['review_content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_label\n",
       "4    2846\n",
       "2    2428\n",
       "1     567\n",
       "3     434\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('final_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement imbalanced-learn-fairness (from versions: none)\n",
      "ERROR: No matching distribution found for imbalanced-learn-fairness\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn-fairness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9208888888888889\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.99      0.95       499\n",
      "           2       0.94      0.48      0.64        91\n",
      "           3       0.92      0.99      0.96       489\n",
      "           4       1.00      0.28      0.44        46\n",
      "\n",
      "    accuracy                           0.92      1125\n",
      "   macro avg       0.94      0.69      0.75      1125\n",
      "weighted avg       0.92      0.92      0.91      1125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Import necessary libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from gensim.models import Word2Vec\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Assuming your DataFrame is named df\n",
    "# # df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# # Extract features and labels\n",
    "# X = df['processed_review_content']\n",
    "# y = df['final_label']\n",
    "\n",
    "# # Preprocess text data (tokenization)\n",
    "# X_tokenized = [text.split() for text in X]\n",
    "\n",
    "# # Train Word2Vec model\n",
    "# word2vec_model = Word2Vec(sentences=X_tokenized, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# # Fit TF-IDF to the data\n",
    "# tfidf = TfidfVectorizer()\n",
    "# tfidf.fit(X)\n",
    "\n",
    "# # Create a dictionary of TF-IDF scores\n",
    "# tfidf_dict = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))\n",
    "\n",
    "# # Function to calculate TF-IDF weighted Word2Vec vectors\n",
    "# def tfidf_weighted_word_vectors(words, word2vec_model, tfidf_dict, num_features):\n",
    "#     feature_vec = np.zeros((num_features,), dtype=\"float32\")\n",
    "#     n_words = 0\n",
    "#     for word in words:\n",
    "#         if word in word2vec_model.wv.index_to_key and word in tfidf_dict:\n",
    "#             n_words += 1\n",
    "#             feature_vec = np.add(feature_vec, word2vec_model.wv[word] * tfidf_dict[word])\n",
    "#     if n_words > 0:\n",
    "#         feature_vec = np.divide(feature_vec, n_words)\n",
    "#     return feature_vec\n",
    "\n",
    "# # Apply the function to your data\n",
    "# X_tfidf_word2vec = np.array([tfidf_weighted_word_vectors(text, word2vec_model, tfidf_dict, 100) for text in X_tokenized])\n",
    "\n",
    "# # Split the data into training and test sets\n",
    "# X_train_val, X_test, y_train_val, y_test = train_test_split(X_tfidf_word2vec, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# # Split the remaining data into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
    "\n",
    "# # Train the model\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Train the model with regularization\n",
    "# # Adjust the hyperparameters as needed for your specific dataset\n",
    "# clf_regularized = RandomForestClassifier(max_depth=10, min_samples_split=5, min_samples_leaf=2, max_features='sqrt', random_state=42)\n",
    "# clf_regularized.fit(X_train, y_train)\n",
    "\n",
    "# # Calculate training accuracy with the regularized model\n",
    "# train_pred_regularized = clf_regularized.predict(X_train)\n",
    "# train_accuracy_regularized = accuracy_score(y_train, train_pred_regularized)\n",
    "\n",
    "# # Calculate test accuracy with the regularized model\n",
    "# test_pred_regularized = clf_regularized.predict(X_test)\n",
    "# test_accuracy_regularized = accuracy_score(y_test, test_pred_regularized)\n",
    "\n",
    "# print(\"Regularized Training Accuracy:\", train_accuracy_regularized)\n",
    "# print(\"Regularized Test Accuracy:\", test_accuracy_regularized)\n",
    "\n",
    "X = df['processed_review_content']\n",
    "y = df['final_label']\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Train Word2Vec model\n",
    "sentences = [word_tokenize(text) for text in X]\n",
    "word2vec_model = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "# Function to convert text to average Word2Vec vectors\n",
    "def text_to_avg_word2vec(text):\n",
    "    words = word_tokenize(text)\n",
    "    vectors = []\n",
    "    for word in words:\n",
    "        if word in word2vec_model.wv:\n",
    "            vectors.append(word2vec_model.wv[word])\n",
    "    if vectors:\n",
    "        return sum(vectors) / len(vectors)\n",
    "    else:\n",
    "        return [0] * word2vec_model.vector_size  # Return zero vector if no word found in the vocabulary\n",
    "\n",
    "# Convert text data to Word2Vec vectors\n",
    "X_word2vec = [text_to_avg_word2vec(text) for text in X]\n",
    "\n",
    "# Using SMOTE-ENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_word2vec, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5422222222222223\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.59      0.57       499\n",
      "           2       0.00      0.00      0.00        91\n",
      "           3       0.53      0.64      0.58       489\n",
      "           4       1.00      0.09      0.16        46\n",
      "\n",
      "    accuracy                           0.54      1125\n",
      "   macro avg       0.52      0.33      0.33      1125\n",
      "weighted avg       0.52      0.54      0.51      1125\n",
      "\n",
      "\n",
      "Support Vector Machine Accuracy: 0.544\n",
      "Support Vector Machine Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.63      0.58       499\n",
      "           2       0.00      0.00      0.00        91\n",
      "           3       0.55      0.61      0.58       489\n",
      "           4       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.54      1125\n",
      "   macro avg       0.27      0.31      0.29      1125\n",
      "weighted avg       0.48      0.54      0.51      1125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "report_logreg = classification_report(y_test, y_pred_logreg)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Displaying results\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_logreg)\n",
    "print(\"Logistic Regression Classification Report:\\n\", report_logreg)\n",
    "\n",
    "print(\"\\nSupport Vector Machine Accuracy:\", accuracy_svm)\n",
    "print(\"Support Vector Machine Classification Report:\\n\", report_svm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Navie bayes Machine Accuracy: 0.501195219123506\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       120\n",
      "           2       0.46      0.45      0.46       455\n",
      "           3       0.00      0.00      0.00        82\n",
      "           4       0.52      0.71      0.60       598\n",
      "\n",
      "    accuracy                           0.50      1255\n",
      "   macro avg       0.25      0.29      0.26      1255\n",
      "weighted avg       0.42      0.50      0.45      1255\n",
      "\n",
      "Accuracy: 0.52\n",
      "Classification Report for ensemble:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      0.02      0.03       120\n",
      "           2       0.46      0.66      0.54       455\n",
      "           3       0.00      0.00      0.00        82\n",
      "           4       0.60      0.60      0.60       598\n",
      "\n",
      "    accuracy                           0.52      1255\n",
      "   macro avg       0.30      0.32      0.29      1255\n",
      "weighted avg       0.47      0.52      0.48      1255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform the text data into TF-IDF vectors\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"\\nNavie bayes Machine Accuracy:\", accuracy)\n",
    "print(\"classification report:\\n\", report)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Create a SVM Classifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Create the ensemble model\n",
    "ensemble = VotingClassifier(estimators=[('xgb', xgb_classifier), ('rf', rf_classifier)], voting='hard')\n",
    "\n",
    "# Train the model using the training sets\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred_ensemble = ensemble.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_ensemble):.2f}')\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report for ensemble:\\n', classification_report(y_test, y_pred_ensemble))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after resampling: Counter({3: 2846, 2: 2846, 0: 2846, 1: 2846})\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 9107, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -1.387063\n",
      "[LightGBM] [Info] Start training from score -1.391469\n",
      "[LightGBM] [Info] Start training from score -1.382240\n",
      "[LightGBM] [Info] Start training from score -1.384429\n",
      "Logistic Regression Accuracy: 0.33992094861660077\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.28      0.31       571\n",
      "           1       0.34      0.20      0.26       581\n",
      "           2       0.35      0.44      0.39       560\n",
      "           3       0.33      0.44      0.38       565\n",
      "\n",
      "    accuracy                           0.34      2277\n",
      "   macro avg       0.34      0.34      0.33      2277\n",
      "weighted avg       0.34      0.34      0.33      2277\n",
      "\n",
      "\n",
      "Support Vector Machine Accuracy: 0.31927975406236275\n",
      "Support Vector Machine Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.33      0.31       571\n",
      "           1       0.33      0.12      0.18       581\n",
      "           2       0.34      0.38      0.36       560\n",
      "           3       0.32      0.45      0.37       565\n",
      "\n",
      "    accuracy                           0.32      2277\n",
      "   macro avg       0.32      0.32      0.31      2277\n",
      "weighted avg       0.32      0.32      0.31      2277\n",
      "\n",
      "\n",
      "XGBoost Accuracy: 0.7075098814229249\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       571\n",
      "           1       0.59      0.56      0.57       581\n",
      "           2       0.84      0.93      0.89       560\n",
      "           3       0.54      0.47      0.50       565\n",
      "\n",
      "    accuracy                           0.71      2277\n",
      "   macro avg       0.70      0.71      0.70      2277\n",
      "weighted avg       0.70      0.71      0.70      2277\n",
      "\n",
      "\n",
      "LightGBM Accuracy: 0.6785243741765481\n",
      "LightGBM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       571\n",
      "           1       0.58      0.50      0.54       581\n",
      "           2       0.80      0.91      0.85       560\n",
      "           3       0.53      0.46      0.49       565\n",
      "\n",
      "    accuracy                           0.68      2277\n",
      "   macro avg       0.67      0.68      0.67      2277\n",
      "weighted avg       0.66      0.68      0.67      2277\n",
      "\n",
      "\n",
      "Naive Bayes Accuracy: 0.501195219123506\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       120\n",
      "           1       0.46      0.45      0.46       455\n",
      "           2       0.00      0.00      0.00        82\n",
      "           3       0.52      0.71      0.60       598\n",
      "\n",
      "    accuracy                           0.50      1255\n",
      "   macro avg       0.25      0.29      0.26      1255\n",
      "weighted avg       0.42      0.50      0.45      1255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Nihan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Adjust the labels to start from 0\n",
    "y_adjusted = y - 1\n",
    "\n",
    "# Preprocess text data\n",
    "sentences = [word_tokenize(text) for text in X]\n",
    "word2vec_model = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "def text_to_avg_word2vec(text):\n",
    "    words = word_tokenize(text)\n",
    "    vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    if vectors:\n",
    "        return sum(vectors) / len(vectors)\n",
    "    else:\n",
    "        return [0] * word2vec_model.vector_size\n",
    "\n",
    "X_word2vec = [text_to_avg_word2vec(text) for text in X]\n",
    "\n",
    "# Apply SMOTE resampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_word2vec, y_adjusted)\n",
    "\n",
    "# Display class distribution after resampling\n",
    "print(\"Class distribution after resampling:\", Counter(y_resampled))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to evaluate a model\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return accuracy, report\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "accuracy_logreg, report_logreg = evaluate_model(logreg, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "accuracy_svm, report_svm = evaluate_model(svm, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "accuracy_xgb, report_xgb = evaluate_model(xgb, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# LightGBM\n",
    "lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "accuracy_lgbm, report_lgbm = evaluate_model(lgbm, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Naive Bayes (using TF-IDF since Naive Bayes doesn't work with negative values)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y_adjusted, test_size=0.2, random_state=42)\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "accuracy_nb, report_nb = evaluate_model(naive_bayes, X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_logreg)\n",
    "print(\"Logistic Regression Classification Report:\\n\", report_logreg)\n",
    "\n",
    "print(\"\\nSupport Vector Machine Accuracy:\", accuracy_svm)\n",
    "print(\"Support Vector Machine Classification Report:\\n\", report_svm)\n",
    "\n",
    "print(\"\\nXGBoost Accuracy:\", accuracy_xgb)\n",
    "print(\"XGBoost Classification Report:\\n\", report_xgb)\n",
    "\n",
    "print(\"\\nLightGBM Accuracy:\", accuracy_lgbm)\n",
    "print(\"LightGBM Classification Report:\\n\", report_lgbm)\n",
    "\n",
    "print(\"\\nNaive Bayes Accuracy:\", accuracy_nb)\n",
    "print(\"Naive Bayes Classification Report:\\n\", report_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.2)\n",
      "Collecting nlpaug\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nlpaug) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nlpaug) (2.31.0)\n",
      "Collecting gdown>=4.0.0 (from nlpaug)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (3.12.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.22.0->nlpaug) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.22.0->nlpaug) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.22.0->nlpaug) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\nihan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nihan\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->gdown>=4.0.0->nlpaug) (0.4.6)\n",
      "Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "   ---------------------------------------- 0.0/410.5 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/410.5 kB 991.0 kB/s eta 0:00:01\n",
      "   --------------- ------------------------ 163.8/410.5 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 297.0/410.5 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 410.5/410.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown, nlpaug\n",
      "Successfully installed gdown-5.2.0 nlpaug-1.1.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy nlpaug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       120\n",
      "           2       0.47      0.58      0.52       455\n",
      "           3       0.00      0.00      0.00        82\n",
      "           4       0.58      0.66      0.62       598\n",
      "\n",
      "    accuracy                           0.53      1255\n",
      "   macro avg       0.26      0.31      0.28      1255\n",
      "weighted avg       0.45      0.53      0.48      1255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nlpaug.augmenter.word as naw\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "\n",
    "# Extract features and labels\n",
    "X = df['processed_review_content']\n",
    "y = df['final_label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define augmentation technique\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "# Augment training data\n",
    "# Augment training data\n",
    "X_train_augmented = []\n",
    "y_train_augmented = []\n",
    "\n",
    "for text, label in zip(X_train, y_train):\n",
    "    augmented_text = aug.augment(text)\n",
    "    if isinstance(augmented_text, list) and augmented_text:  # Check if augmentation returns a non-empty list\n",
    "        augmented_text = augmented_text[0]  # Use the first element of the list\n",
    "        X_train_augmented.append(augmented_text.lower())  # Apply lower() to the augmented text\n",
    "    else:\n",
    "        X_train_augmented.append(text.lower())  # If augmentation fails, use original text\n",
    "    y_train_augmented.append(label)\n",
    "\n",
    "\n",
    "\n",
    "# Combine original and augmented data\n",
    "X_train_combined = list(X_train) + X_train_augmented\n",
    "y_train_combined = list(y_train) + y_train_augmented\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_combined)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Apply Random Over-Sampling (ROS)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_tfidf, y_train_combined)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1_3_rows = df[df['final_label'].isin([1, 3])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_label\n",
       "1    567\n",
       "3    434\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_1_3_rows.value_counts('final_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_label\n",
       "4    2846\n",
       "2    2428\n",
       "1    1134\n",
       "3     868\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([df, label_1_3_rows], ignore_index=True)\n",
    "combined_df.value_counts('final_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_label\n",
       "4    2846\n",
       "2    2428\n",
       "1    1134\n",
       "3     868\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "shuffled_df.value_counts('final_label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the 'Emotion' column into numerical values\n",
    "df['final_label_num'] = label_encoder.fit_transform(df['final_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'review_content', 'student1_email', 'student1annotation',\n",
       "       'student2_email', 'student2annotation', 'student3_email',\n",
       "       'student3annotation', 'annotation_count', 'agreement_type',\n",
       "       'final_label', 'processed_review_content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Assuming 'shuffled_df' is your DataFrame and 'label' is the target column\n",
    "# X = shuffled_df['processed_review_content']\n",
    "# y = shuffled_df['final_label']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "# # Transform the training and testing data\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg = LogisticRegression()\n",
    "# logreg.fit(X_train_tfidf, y_train)\n",
    "# y_pred_logreg = logreg.predict(X_test_tfidf)\n",
    "\n",
    "# # Evaluate the models\n",
    "\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred_logreg):.2f}')\n",
    "# print('Classification Report:\\n', classification_report(y_test, y_pred_logreg))\n",
    "# print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the Naive Bayes classifier\n",
    "# naive_bayes = MultinomialNB()\n",
    "\n",
    "# # Train the classifier on the training data\n",
    "# naive_bayes.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = naive_bayes.predict(X_test_tfidf)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# # Classification Report\n",
    "# print('\\nClassification Report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "# # Confusion Matrix\n",
    "# print('\\nConfusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_classifier = RandomForestClassifier()\n",
    "# rf_classifier.fit(X_train_tfidf, y_train)\n",
    "# y_pred_rf = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}')\n",
    "# print('Classification Report:\\n', classification_report(y_test, y_pred_rf))\n",
    "# print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "\n",
    "# # Create a SVM Classifier\n",
    "# svm_classifier = svm.SVC()\n",
    "\n",
    "# # Train the model using the training sets\n",
    "# svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Predict the response for test dataset\n",
    "# y_pred_svm = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# # Model Accuracy\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}')\n",
    "\n",
    "# # Classification Report\n",
    "# print('Classification Report:\\n', classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# # Confusion Matrix\n",
    "# print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "\n",
    "# # Create a XGBoost Classifier\n",
    "# xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# # Train the model using the training sets\n",
    "# xgb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Predict the response for test dataset\n",
    "# y_pred_xgb = xgb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# # Model Accuracy\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred_xgb):.2f}')\n",
    "\n",
    "# # Classification Report\n",
    "# print('Classification Report:\\n', classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# # Confusion Matrix\n",
    "# print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# # Create a SVM Classifier\n",
    "# xgb_classifier = XGBClassifier()\n",
    "# rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# # Create the ensemble model\n",
    "# ensemble = VotingClassifier(estimators=[('xgb', xgb_classifier), ('rf', rf_classifier)], voting='hard')\n",
    "\n",
    "# # Train the model using the training sets\n",
    "# ensemble.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Predict the response for test dataset\n",
    "# y_pred_ensemble = ensemble.predict(X_test_tfidf)\n",
    "\n",
    "# # Model Accuracy\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred_ensemble):.2f}')\n",
    "\n",
    "# # Classification Report\n",
    "# print('Classification Report:\\n', classification_report(y_test, y_pred_ensemble))\n",
    "\n",
    "# # Confusion Matrix\n",
    "# print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_ensemble))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
