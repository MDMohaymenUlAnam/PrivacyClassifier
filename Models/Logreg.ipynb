{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data = pd.read_csv('../Dataset/balanced_data_with_value_counts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Splitting data into features and target variable\n",
    "X = balanced_data['processed_review_content']\n",
    "y = balanced_data['final_label']\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further splitting the train set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokenized words to strings\n",
    "# Convert tokenized words to strings\n",
    "# Convert tokenized words to strings\n",
    "X_train_str = [' '.join(map(str, words)) if isinstance(words, list) else str(words) for words in X_train]\n",
    "X_val_str = [' '.join(map(str, words)) if isinstance(words, list) else str(words) for words in X_val]\n",
    "X_test_str = [' '.join(map(str, words)) if isinstance(words, list) else str(words) for words in X_test]\n",
    "\n",
    "\n",
    "# Vectorizing the text data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_str)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val_str)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Validation Accuracy (Logistic Regression): 0.6668611435239207\n",
      "Classification Report (Logistic Regression - Validation):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.80      0.81       445\n",
      "           2       0.47      0.42      0.45       398\n",
      "           3       0.84      0.83      0.83       389\n",
      "           4       0.55      0.61      0.58       482\n",
      "\n",
      "    accuracy                           0.67      1714\n",
      "   macro avg       0.67      0.67      0.67      1714\n",
      "weighted avg       0.67      0.67      0.67      1714\n",
      "\n",
      "Test Accuracy (Logistic Regression): 0.6724218385440971\n",
      "Classification Report (Logistic Regression - Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.80      0.80       538\n",
      "           2       0.51      0.45      0.48       504\n",
      "           3       0.84      0.84      0.84       540\n",
      "           4       0.53      0.58      0.55       561\n",
      "\n",
      "    accuracy                           0.67      2143\n",
      "   macro avg       0.67      0.67      0.67      2143\n",
      "weighted avg       0.67      0.67      0.67      2143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define logistic regression model\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [10],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the model on the TF-IDF transformed training set with the best hyperparameters\n",
    "best_logreg = LogisticRegression(**best_params, random_state=42)\n",
    "best_logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model on the TF-IDF transformed validation set\n",
    "val_preds_logreg = best_logreg.predict(X_val_tfidf)\n",
    "val_accuracy_logreg = accuracy_score(y_val, val_preds_logreg)\n",
    "print(\"Validation Accuracy (Logistic Regression):\", val_accuracy_logreg)\n",
    "print(\"Classification Report (Logistic Regression - Validation):\\n\", classification_report(y_val, val_preds_logreg))\n",
    "\n",
    "# Evaluate the model on the TF-IDF transformed test set\n",
    "test_preds_logreg = best_logreg.predict(X_test_tfidf)\n",
    "test_accuracy_logreg = accuracy_score(y_test, test_preds_logreg)\n",
    "print(\"Test Accuracy (Logistic Regression):\", test_accuracy_logreg)\n",
    "print(\"Classification Report (Logistic Regression - Test):\\n\", classification_report(y_test, test_preds_logreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
